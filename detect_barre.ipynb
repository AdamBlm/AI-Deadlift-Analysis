import cv2
from ultralytics import YOLO

def process_video(video_path, output_path, model_path='yolov8n.pt'):
    """
    Detects the deadlift barrier in a video using YOLO and outputs its position for each frame.
    Args:
        video_path (str): Path to the input video.
        output_path (str): Path to save the output video.
        model_path (str): Path to the YOLO model file. Defaults to 'yolov8n.pt' (pre-trained model).
    """
    # Load the YOLO model
    model = YOLO(model_path)

    # Open the video
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Cannot open video file.")
        return

    # Get video properties
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Prepare the output video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    frame_positions = []

    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Perform inference
        results = model(frame)

        # Initialize variables for tracking
        barrier_positions = []

        # Loop through detections
        for result in results:
            boxes = result.boxes
            for box in boxes:
                # Check if the detected class is the deadlift barrier
                # Replace 'deadlift_barrier_class_id' with the correct class ID for the barrier
                if box.cls == 'deadlift_barrier_class_id':
                    x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates
                    barrier_positions.append((x1, y1, x2, y2))
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Draw bounding box
                    cv2.putText(frame, f"Deadlift Barrier", (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        # Save positions for this frame
        frame_positions.append({'frame_idx': frame_idx, 'positions': barrier_positions})

        # Write the frame to the output video
        out.write(frame)

        # Update frame index
        frame_idx += 1

        # Optional: Display the frame for debugging
        # cv2.imshow('YOLO Deadlift Barrier Detection', frame)
        # if cv2.waitKey(1) & 0xFF == ord('q'):
        #     break

    # Release resources
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # Print positions
    print("Barrier positions per frame:")
    for item in frame_positions:
        print(item)

# Example usage
# Replace 'video.mp4' with the path to your input video
# Replace 'output.mp4' with the desired output path
# Replace 'custom_yolo_model.pt' with your trained model path if necessary
process_video('video.mp4', 'output.mp4', model_path='custom_yolo_model.pt')
